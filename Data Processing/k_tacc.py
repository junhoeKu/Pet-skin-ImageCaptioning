# -*- coding: utf-8 -*-
"""K_TACC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u4csbJuhHmfBYdukwWRJWvLAxZQY9wM7
"""

# !git clone https://github.com/kyle-bong/K-TACC.git

!bash install.sh

import pandas as pd
from BERT_augmentation import BERT_Augmentation
import transformers
from multiprocessing import Pool


def augment_row(row):
    imgurl, original_text = row[0], row[1]
    augmented_rows = [[imgurl, original_text]] # original text

    BERT_aug = BERT_Augmentation()
    random_masking_insertion = BERT_aug.random_masking_insertion

    # Perform random_masking_insertion augmentation with different ratios
    for ratio in [0.15, 0.3]:
        text_aug = random_masking_insertion(sentence=original_text[:512], ratio=ratio)
        if 512 <= len(original_text) < 1024:
            text_aug += random_masking_insertion(sentence=original_text[512:1024], ratio=ratio)
        elif len(original_text) >= 1024:
            text_aug += random_masking_insertion(sentence=original_text[512:1024], ratio=ratio)
            text_aug += random_masking_insertion(sentence=original_text[1024:1536], ratio=ratio)

        augmented_rows.append([imgurl, text_aug])

    return augmented_rows

def textAug(data: pd.DataFrame):
    print(f'Before text augmentation: {len(data)} rows')

    # Use multiprocessing to speed up the augmentation
    with Pool() as pool:
        results = pool.map(augment_row, data.values)

    # Flatten the list of lists into a single DataFrame
    augmented_df = pd.DataFrame([item for sublist in results for item in sublist], columns=data.columns)

    # Remove duplicate rows based on all columns
    augmented_df.drop_duplicates(inplace=True)

    # Save the augmented DataFrame to a CSV file
    augmented_df.to_csv('textaug_df.csv', encoding='utf-8', index=False)
    print(f'After text augmentation: {len(augmented_df)} rows')